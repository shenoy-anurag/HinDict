{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import sqlite3 as SQL\n",
    "import requests\n",
    "\n",
    "from indic_transliteration.sanscript import transliterate, IAST, DEVANAGARI, HK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/eng-hin/eng-hin-tabfile.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>##name</th>\n",
       "      <th>eng-hin.index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>##sourceLang</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>##targetLang</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00databasealphabet</td>\n",
       "      <td>12abcdefghijklmnopqrstuvwxyz&lt;br /&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00databasedictfmt1121</td>\n",
       "      <td>00-database-dictfmt-1.12.1&lt;br /&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00databaseinfo</td>\n",
       "      <td>English-Hindi FreeDict Dictionary&lt;br /&gt;&lt;br /&gt;M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00databaseshort</td>\n",
       "      <td>English-Hindi FreeDict Dictionary ver. 1.6&lt;br /&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00databaseurl</td>\n",
       "      <td>unknown&lt;br /&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00databaseutf8</td>\n",
       "      <td>&lt;br /&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>a /ˈeɪ/ &lt;Det&gt;&lt;br /&gt;1. एक&lt;br /&gt;      \"I bought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a feather in ones cap</td>\n",
       "      <td>A feather in one's cap /ɐ fˈɛðəɹ ɪn wˈɒnz kˈap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ##name                                      eng-hin.index\n",
       "0           ##sourceLang                                            English\n",
       "1           ##targetLang                                              Hindi\n",
       "2     00databasealphabet                 12abcdefghijklmnopqrstuvwxyz<br />\n",
       "3  00databasedictfmt1121                   00-database-dictfmt-1.12.1<br />\n",
       "4         00databaseinfo  English-Hindi FreeDict Dictionary<br /><br />M...\n",
       "5        00databaseshort   English-Hindi FreeDict Dictionary ver. 1.6<br />\n",
       "6          00databaseurl                                      unknown<br />\n",
       "7         00databaseutf8                                             <br />\n",
       "8                      a  a /ˈeɪ/ <Det><br />1. एक<br />      \"I bought ...\n",
       "9  a feather in ones cap  A feather in one's cap /ɐ fˈɛðəɹ ɪn wˈɒnz kˈap..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = df[8:].copy()\n",
    "dict_df.rename({'##name': 'word/phrase', 'eng-hin.index': 'definition'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def romanized_to_devanagari(word):\n",
    "    \"\"\"\n",
    "    Converts a Romanized Hindi word into Devanagari.\n",
    "    :param word: Romanized Hindi word (string)\n",
    "    :return: Devanagari script equivalent (string)\n",
    "    \"\"\"\n",
    "    return transliterate(word, IAST, DEVANAGARI)\n",
    "\n",
    "\n",
    "def devanagari_to_romanized(word):\n",
    "    \"\"\"\n",
    "    Converts a Devanagari Hindi word into Romanized Hindi.\n",
    "    :param word: Devanagari script equivalent (string)\n",
    "    :return: Romanized Hindi word (string)\n",
    "    \"\"\"\n",
    "    return transliterate(word, DEVANAGARI, IAST)\n",
    "\n",
    "def devanagari_to_romanized_hk(word):\n",
    "    \"\"\"\n",
    "    Converts a Devanagari Hindi word into Romanized Hindi.\n",
    "    :param word: Devanagari script equivalent (string)\n",
    "    :return: Romanized Hindi word (string)\n",
    "    \"\"\"\n",
    "    return transliterate(word, DEVANAGARI, HK)\n",
    "\n",
    "\n",
    "def parse_definition(definition_text):\n",
    "    # Split input by parts of speech based on <N> and <VT> markers\n",
    "    # parts = re.split(r'<([NVIT]+)>', definition_text)\n",
    "    parts = re.split(r'<([NVVIVTAdjAdvPronPrepConjDetNumInterjIDMPhrvAbbrSlExclAuxPlArt]+)>', definition_text)\n",
    "\n",
    "    # Extract the word and pronunciation\n",
    "    word_section = parts[0].strip()\n",
    "    # pattern_word_section = r\"^([\\w\\s]+)\\s/([^/]+)/\"\n",
    "    # pattern_word_section = r\"^([\\w\\s]+)\\s/([ˈˌaæbddʒefghijklmnŋoɔprstt̬tʃuvwxɐɑɒɑ̃ɚəɜɝɛɪʃʊʌʒθð\\s]+)/\"\n",
    "    # pattern_word_section = r\"([\\w\\d\\s'.]+)\\/([aäɑɒæbḇβcčɔɕçdḏḍðeəɚɛɝfgḡhʰḥḫẖiɪỉɨjʲǰkḳḵlḷɬɫmnŋṇɲɴoŏɸθpp̅þqrɹɾʀʁṛsšśṣʃtṭṯʨtʂuʊŭüvʌɣwʍxχyʸʎzẓžʒ’‘ʔʕ\\s]+)\\/\"\n",
    "    pattern_word_section = r\"([\\w\\d\\s'.\\-()~]+)\\/(.+)\\/\"\n",
    "    word, pronunciation = re.match(\n",
    "        pattern_word_section, word_section).groups()\n",
    "\n",
    "    word = word.strip()\n",
    "\n",
    "    # Initialize result structure\n",
    "    result = {\n",
    "        \"word\": word,\n",
    "        \"pronunciation\": pronunciation,\n",
    "        \"entries\": []\n",
    "    }\n",
    "\n",
    "    # Process each POS section\n",
    "    for i in range(1, len(parts) - 1, 2):\n",
    "        part_of_speech = parts[i].strip()\n",
    "        raw_definitions = parts[i + 1].strip()\n",
    "\n",
    "        # Map POS markers to human-readable forms\n",
    "        pos_map = {\n",
    "            \"N\": \"Noun\",\n",
    "            \"V\": \"Verb\",\n",
    "            \"VI\": \"Verb (Intransitive)\",\n",
    "            \"VT\": \"Verb (Transitive)\",\n",
    "            \"Adj\": \"Adjective\",\n",
    "            \"Adv\": \"Adverb\",\n",
    "            \"Pron\": \"Pronoun\",\n",
    "            \"Prep\": \"Preposition\",\n",
    "            \"Conj\": \"Conjunction\",\n",
    "            \"Det\": \"Determiner\",\n",
    "            \"Num\": \"Numeral\",\n",
    "            \"Interj\": \"Interjection\",\n",
    "            \"IDM\": \"Idiom\",\n",
    "            \"Phrv\": \"Phrasal Verb\",\n",
    "            \"Abbr\": \"Abbreviation\",\n",
    "            \"Sl\": \"Slang\",\n",
    "            \"Excl\": \"Exclamation\",\n",
    "            \"Aux\": \"Auxiliary Verb\",\n",
    "            \"Pl\": \"Plural\",\n",
    "            \"Art\": \"Article\"\n",
    "        }\n",
    "        pos_name = pos_map.get(part_of_speech, part_of_speech)\n",
    "\n",
    "        # Parse definitions\n",
    "        definitions = []\n",
    "        for entry in re.split(r'\\d+\\.\\s', raw_definitions)[1:]:\n",
    "            match = re.match(r'([^<]+)<br\\s*/>\\s*\"([^\"]+)\"', entry, re.DOTALL)\n",
    "            if match:\n",
    "                hindi, example = match.groups()\n",
    "                hindi_word = hindi.strip().replace('~', ' ')\n",
    "                definitions.append({\n",
    "                    \"hindi\": hindi_word,\n",
    "                    \"romanized_iast\": devanagari_to_romanized(hindi_word),\n",
    "                    \"romanized_hk\": devanagari_to_romanized_hk(hindi_word),\n",
    "                    \"example\": example.strip()\n",
    "                })\n",
    "\n",
    "        # Add parsed data to the entries\n",
    "        result[\"entries\"].append({\n",
    "            \"part_of_speech\": pos_name,\n",
    "            \"definitions\": definitions\n",
    "        })\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag[stone] /flˈaɡ stˈəʊn/\n",
      "keep in with <a href=\"bword://infl\">infl</a> /kˈiːp ɪn wɪð ˈɪnfəl/\n",
      "not care\\\\give a fig /nˌɒt kˈeə bˈakslaʃ ɡˈɪv ɐ fˈɪɡ/\n",
      "pell-?????? /pˈɛl/\n",
      "raise (US=rise) /ɹˈeɪz jˌuːˈɛs ˈiːkwəlz ɹˈaɪz/\n",
      "tu-whit,tu-whoo /tˈuːwˈɪt tˈuːwˈuː/\n",
      "wellington[boot] /wˈɛlɪŋtən bˈuːt/\n",
      "22864\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "all_words = {}\n",
    "\n",
    "word = ''\n",
    "unparsed_words = []\n",
    "for row in dict_df.itertuples():\n",
    "    index = row[0]\n",
    "    word = row[1]\n",
    "    data = row[2]\n",
    "    try:\n",
    "        parsed_data = parse_definition(data)\n",
    "        all_words[word] = parsed_data\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        parts = re.split(r'<([NVVIVTAdjAdvPronPrepConjDetNumInterjIDMPhrvAbbrSlExclAuxPlArt]+)>', data)\n",
    "        word_section = parts[0].strip()\n",
    "        print(word_section)\n",
    "        unparsed_words.append(word)\n",
    "\n",
    "with open('../data/eng-hin/eng-hin-parsed.json', 'w') as f:\n",
    "    f.write(json.dumps(all_words))\n",
    "    print(len(list(all_words.keys())))\n",
    "\n",
    "with open('../data/eng-hin/eng-hin-unparsed.json', 'w') as f:\n",
    "    f.write(json.dumps(unparsed_words))\n",
    "    print(len(unparsed_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dakṣiṇī aphrīkā kī janajātī\n"
     ]
    }
   ],
   "source": [
    "print(\"dak\\u1e63i\\u1e47\\u012b aphr\\u012bk\\u0101 k\\u012b janaj\\u0101t\\u012b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_hindi_to_english_dict(english_to_hindi_dict):\n",
    "    hindi_to_english_dict = {}\n",
    "    hindi_to_english_dict_hk = {}\n",
    "\n",
    "    for entry in english_to_hindi_dict.values():\n",
    "        word = entry[\"word\"]\n",
    "        for pos_entry in entry[\"entries\"]:\n",
    "            for definition in pos_entry[\"definitions\"]:\n",
    "                # Add Hindi words as keys\n",
    "                for hindi_word in definition[\"hindi\"].split(\", \"):  # Split multiple Hindi meanings\n",
    "                    hindi_word = hindi_word.replace('~', '')\n",
    "                    if hindi_word not in hindi_to_english_dict:\n",
    "                        hindi_to_english_dict[hindi_word] = []\n",
    "                    hindi_to_english_dict[hindi_word].append(word)\n",
    "\n",
    "                # Add Romanized Harvard-Kyoto words as keys\n",
    "                for romanized_word in definition[\"romanized_hk\"].split(\", \"):  # Split multiple romanized words\n",
    "                    romanized_word = romanized_word.replace('~', '')\n",
    "                    if romanized_word not in hindi_to_english_dict_hk:\n",
    "                        hindi_to_english_dict_hk[romanized_word] = []\n",
    "                    hindi_to_english_dict_hk[romanized_word].append(word)\n",
    "\n",
    "    return hindi_to_english_dict, hindi_to_english_dict_hk\n",
    "\n",
    "\n",
    "# Convert to Hindi-to-English dictionary\n",
    "hindi_to_english_dict, hindi_to_english_dict_hk = convert_to_hindi_to_english_dict(all_words)\n",
    "\n",
    "# store the result\n",
    "with open('../data/eng-hin/hi-en-mapping.json', 'w') as f:\n",
    "    f.write(json.dumps(hindi_to_english_dict))\n",
    "    \n",
    "with open('../data/eng-hin/hi-en-hk-mapping.json', 'w') as f:\n",
    "    f.write(json.dumps(hindi_to_english_dict_hk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eka', 'kaThina kArya ko karanA', 'kucha', 'nirNAyaka lar3AI', 'kArya kI saphalatA kI thor3I AzA']\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "hindi_to_english_dict = None\n",
    "with open('../data/eng-hin/hi-en-mapping.json', 'r') as f:\n",
    "    hindi_to_english_dict = json.load(f)\n",
    "\n",
    "hindi_to_english_dict_hk = None\n",
    "with open('../data/eng-hin/hi-en-hk-mapping.json', 'r') as f:\n",
    "    hindi_to_english_dict_hk = json.load(f)\n",
    "\n",
    "print(list(hindi_to_english_dict_hk.keys())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * from entries where word='hair's-breadth'\n",
      "near \"s\": syntax error\n",
      "SELECT * from entries where word='hors-d'oeuvre'\n",
      "near \"oeuvre\": syntax error\n",
      "SELECT * from entries where word='knacker's-yard'\n",
      "near \"s\": syntax error\n",
      "SELECT * from entries where word='knacker's-yard'\n",
      "near \"s\": syntax error\n",
      "SELECT * from entries where word='ma'am'\n",
      "near \"am\": syntax error\n",
      "SELECT * from entries where word='ma'am'\n",
      "near \"am\": syntax error\n",
      "SELECT * from entries where word='o'clock'\n",
      "near \"clock\": syntax error\n",
      "SELECT * from entries where word='outre''\n",
      "unrecognized token: \"'outre''\"\n",
      "SELECT * from entries where word='piracy'\n",
      "can only concatenate str (not \"NoneType\") to str\n",
      "SELECT * from entries where word='piracy'\n",
      "can only concatenate str (not \"NoneType\") to str\n",
      "SELECT * from entries where word='rapid'transit''\n",
      "near \"transit\": syntax error\n"
     ]
    }
   ],
   "source": [
    "conn = SQL.connect(\"../data/english-dictionary-cloudbytes.db\")\n",
    "\n",
    "def get_definition(word):\n",
    "    try:\n",
    "        db = conn.cursor()\n",
    "        query = \"SELECT * from entries where word='{}'\".format(word)\n",
    "        db.execute(query)\n",
    "        output = db.fetchall()\n",
    "        db.close()\n",
    "        return [word, [o[1] + \" \" + o[2] for o in output if o[1]]]\n",
    "    except Exception as e:\n",
    "        print(query)\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def get_definition_api(word):\n",
    "    url = 'https://api.dictionaryapi.dev/api/v2/entries/en/' + word\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        resp_list = response.json()\n",
    "        resp_dict = resp_list[0]\n",
    "        return [m['partOfSpeech'] + \" \" + d['definition'] for m in resp_dict['meanings'] for d in m['definitions']]\n",
    "\n",
    "\n",
    "def prep_documents(english_to_hindi_dict):\n",
    "    documents = []\n",
    "    for hindi_word, english_words in english_to_hindi_dict.items():\n",
    "        for w in english_words:\n",
    "            if len(w.split()) == 1:\n",
    "                definition = get_definition(w)\n",
    "                if definition:\n",
    "                    text = hindi_word + \" | \" + w + \" | \" + \"\\n\" + \"\\n\".join(definition[1])\n",
    "                    documents.append(text)\n",
    "                else:\n",
    "                    definition = get_definition_api(w)\n",
    "                    if definition:\n",
    "                        text = hindi_word + \" | \" + w + \" | \" + \"\\n\" + \"\\n\".join(definition)\n",
    "                        documents.append(text)\n",
    "    return documents\n",
    "\n",
    "documents = prep_documents(hindi_to_english_dict_hk)\n",
    "\n",
    "with open('../data/eng-hin/hi-en-documents.json', 'w') as f:\n",
    "    f.write(json.dumps({'documents': documents}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmDictPy312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
